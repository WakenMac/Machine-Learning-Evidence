# ğŸ¹ Real PianoMotion10M Setup & Usage Guide

## Quick Start

### Option 1: Automatic Setup (Recommended)
```bash
cd Code/Data_Pipeline
python setup_real_dataset.py
```

This interactive script will guide you through:
1. âœ… Checking dependencies
2. ğŸ“¥ Downloading the real dataset
3. âš™ï¸ Preparing features
4. ğŸ¤– Training models

### Option 2: Manual Steps

#### Step 1: Check Dependencies
```bash
python setup_real_dataset.py
# Select option 1
```

#### Step 2: Download Dataset
```bash
python DownloadRealPianoMotion10M.py
```

This downloads ~1-2 GB from GitHub and extracts:
- Hand motion capture data (JSON/NPZ/NPY files)
- MIDI annotation files
- Organizes into `Data/PianoMotion10M/` structure

#### Step 3: Prepare Features
The download script automatically prepares features, but you can also:
```bash
python DownloadRealPianoMotion10M.py
```

Outputs: `Data/PianoMotion10M/features_real_pianomotion10m.csv`

#### Step 4: Train Models
```bash
python ML_Pipeline_Prep.py
```

Trains SVM and Random Forest with hyperparameter tuning.

Outputs:
- `Data/PianoMotion10M/results/model_comparison.csv`
- PNG visualizations (confusion matrices, ROC curves)

---

## File Structure After Setup

```
Data/
â””â”€â”€ PianoMotion10M/
    â”œâ”€â”€ data/                              # Real dataset files
    â”‚   â”œâ”€â”€ subject_1/
    â”‚   â”‚   â”œâ”€â”€ raw_seqs/                 # Motion capture files
    â”‚   â”‚   â””â”€â”€ raw_seqs_labels/          # MIDI annotations
    â”‚   â””â”€â”€ subject_2/
    â”‚       â”œâ”€â”€ raw_seqs/
    â”‚       â””â”€â”€ raw_seqs_labels/
    â”œâ”€â”€ features_real_pianomotion10m.csv  # Prepared ML features
    â”œâ”€â”€ models/                           # Trained model files
    â”‚   â”œâ”€â”€ svm_model.pkl
    â”‚   â”œâ”€â”€ rf_model.pkl
    â”‚   â”œâ”€â”€ scaler.pkl
    â”‚   â””â”€â”€ feature_names.pkl
    â””â”€â”€ results/
        â”œâ”€â”€ model_comparison.csv
        â”œâ”€â”€ confusion_matrices.png
        â””â”€â”€ roc_curves.png

Code/Data_Pipeline/
â”œâ”€â”€ DownloadRealPianoMotion10M.py        # Dataset download & parsing
â”œâ”€â”€ ML_Pipeline_Prep.py                  # Model training
â”œâ”€â”€ PreparePianoMotionDataset.py         # Data preparation
â””â”€â”€ setup_real_dataset.py                # This setup script
```

---

## What's Different: Real vs Synthetic Data

### Current Synthetic Data (500 rows)
- âœ… Good for testing pipeline
- âŒ Doesn't reflect real motion patterns
- âŒ Perfect metrics (98% SVM accuracy)
- âŒ Not representative of real performance

### Real PianoMotion10M Data
- âœ… Authentic hand motion patterns
- âœ… Realistic key press vs hover behavior
- âœ… Generalizes to new piano players
- âœ… Enables reliable deployment
- âš ï¸ Larger download (~1-2 GB)
- âš ï¸ Takes longer to process

---

## Python API Usage

### Using Real Dataset Features in Your Code

```python
import pandas as pd
from pathlib import Path

# Load real dataset features
data_dir = Path("Data/PianoMotion10M")
features_df = pd.read_csv(data_dir / "features_real_pianomotion10m.csv")

print(f"Dataset shape: {features_df.shape}")
print(f"Classes: {features_df['label'].unique()}")
print(f"Features: {list(features_df.columns[:-1])}")

# Split features and labels
X = features_df.drop('label', axis=1)
y = features_df['label']

# Use with ML pipeline
from ML_Pipeline_Prep import PianoMotionMLPipeline

pipeline = PianoMotionMLPipeline(random_state=42)
pipeline.train_models(X, y)
pipeline.evaluate_and_compare()
```

### Real-Time Inference with Trained Models

```python
import pickle
from pathlib import Path

# Load trained model and scaler
model_dir = Path("Data/PianoMotion10M/models")

with open(model_dir / "rf_model.pkl", "rb") as f:
    model = pickle.load(f)

with open(model_dir / "scaler.pkl", "rb") as f:
    scaler = pickle.load(f)

# Predict on new motion sequence
import numpy as np

new_features = np.array([[...]])  # 1x9 feature array
scaled_features = scaler.transform(new_features)
prediction = model.predict(scaled_features)
probability = model.predict_proba(scaled_features)

print(f"Prediction: {'Key Press' if prediction[0] == 1 else 'Hover'}")
print(f"Confidence: {max(probability[0]):.2%}")
```

---

## Deployment Integration

Once you have trained models, integrate with existing code:

### Option A: Direct Integration (Simple)
```python
# In VideoPlayer.py or DetectArucoLive.py
import pickle
from pathlib import Path

model_path = Path("Data/PianoMotion10M/models/rf_model.pkl")
scaler_path = Path("Data/PianoMotion10M/models/scaler.pkl")

with open(model_path, "rb") as f:
    ml_model = pickle.load(f)
with open(scaler_path, "rb") as f:
    ml_scaler = pickle.load(f)

# Replace old threshold logic
def detect_key_press(hand_motion_features):
    scaled = ml_scaler.transform([hand_motion_features])
    return ml_model.predict(scaled)[0]
```

### Option B: Wrapper Class (Recommended)
See `ModelDeployment.py` for `RealtimeMotionClassifier` class that handles:
- Feature extraction
- Real-time buffering
- Confidence scoring
- Performance metrics

---

## Troubleshooting

### Download Fails
```bash
# Check internet connection
ping github.com

# Try manual download from:
# https://github.com/google-research-datasets/pianomotion-10m/releases
```

### Out of Disk Space
The dataset requires:
- ~2 GB for raw download
- ~3 GB total with extracted files
- Free up space or modify `DownloadRealPianoMotion10M.py` to download only specific subjects

### MIDI Parsing Errors
```bash
# Ensure mido is installed
python -m pip install mido
```

### Model Training Takes Too Long
- Reduce `n_iter=20` to `n_iter=10` in `ML_Pipeline_Prep.py` line 85
- Reduce `cv=3` to `cv=2` for faster cross-validation
- Use Random Forest only (comment out SVM section)

---

## Performance Expectations

### Training Time
- SVM hyperparameter tuning: 2-5 minutes
- Random Forest training: 3-8 minutes
- Total: ~5-10 minutes

### Real-Time Inference
- Random Forest: 1000+ FPS (excellent for real-time)
- SVM: 100+ FPS (very good for real-time)

### Expected Accuracy (Real Data)
- SVM: 95-98% (depending on data quality)
- Random Forest: 93-97%
- Will be lower than synthetic (98%) due to real-world complexity

---

## Next Steps

1. âœ… Run setup script
2. âœ… Download and train on real data
3. âœ… Compare synthetic vs real performance
4. âœ… Deploy to piano motion detection application
5. âœ… Benchmark against heuristic-based detection

For deployment into `VideoPlayer.py`, `DetectArucoLive.py`, or `hand_press_detector.py`, see the integration examples above.

